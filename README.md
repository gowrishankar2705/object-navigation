# ğŸ§­ Object Navigation

An AI-powered object navigation system leveraging YOLOv8 for real-time object detection and Text-To-Speech (TTS) for audio feedback, designed to assist in navigation tasks.

---

## ğŸ“˜ About

This project combines advanced computer vision with speech synthesis to create a navigation assistant that detects surrounding objects using the YOLOv8 model and provides spoken guidance or alerts. It is implemented entirely in Python and supports real-time processing.

---

## ğŸš€ Features

- Real-time object detection using YOLOv8 neural network  
- Text-to-Speech integration for actionable audio navigation feedback  
- Efficient processing tailored for navigation use cases  
- Modular Python codebase for easy extension and customization  

---

## ğŸ§  Tech Stack

- **Language:** Python  
- **AI Framework:** PyTorch (YOLOv8 model)  
- **Speech Synthesis:** Any Python TTS library (e.g., pyttsx3, gTTS)  
- **Dependencies:** See `requirements.txt`  

---

## âš™ï¸ Setup & Installation

1. Clone the repository:
git clone https://github.com/gowrishankar2705/object-navigation.git

2. Change to the project directory:
cd object-navigation

3. Create and activate a Python virtual environment (optional but recommended):
python -m venv venv
source venv/bin/activate # Windows: venv\Scripts\activate

4. Install dependencies:
pip install -r requirements.txt

5. Run the main navigation script:
python main.py

---

## ğŸ—‚ï¸ Project Structure

object-navigation/

â”‚

â”œâ”€â”€ main.py # Main script for running navigation system

â”œâ”€â”€ yolov8n.pt # Pretrained YOLOv8 model weights

â”œâ”€â”€ requirements.txt # Python dependencies

â””â”€â”€ other_modules/ # Additional functional modules if any

---

## ğŸ‘¨â€ğŸ’» Author

**Gowrishankar S**  
B.Tech in AI & Data Science 
- GitHub: [@gowrishankar2705](https://github.com/gowrishankar2705)  
- LinkedIn: [in/gowrishankar-s-59a782253](https://www.linkedin.com/in/gowrishankar-s-59a782253/)  

---

## ğŸ“œ License

This project is open-source and licensed under the **MIT License**.  
Feel free to use, modify, and distribute with attribution.

---
